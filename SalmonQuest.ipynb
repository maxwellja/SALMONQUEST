{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd72ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries and change working directory.\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "\n",
    "working_directory = '/Users/maxwell/Desktop/Code/SALMONQUEST/SalmonData'\n",
    "os.chdir(working_directory)\n",
    "currpath = os.getcwd()\n",
    "directory = os.listdir(currpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd945ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Import\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedcc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The Columbia River has 9 salmon counting locations at increasingly-inland points along the river.\n",
    "For each of these dams, I will extract the daily count CSV file for each year from 2006 to 2022.\n",
    "I will create 10 CSV files.\n",
    "There will be 9 long-format CSV files for each dam, each including the entire year range.\n",
    "There will also be one master CSV file. This will be the total collection of data.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Each of the dams' full names and their abbreviation used in the HTTP request.\n",
    "dam_names = {\n",
    "    'Bonneville': 'BON',\n",
    "    'The Dalles': 'TDA',\n",
    "    'John Day': 'JDA',\n",
    "    'McNary': 'MCN',\n",
    "    'Priest Rapids': 'PRD',\n",
    "    'Wanapum': 'WAN',\n",
    "    'Rock Island': 'RIS',\n",
    "    'Rocky Beach': 'RRH',\n",
    "    'Wells': 'WEL'\n",
    "}\n",
    "\n",
    "#Check if data already exists in working directory. If so, an exception is thrown.\n",
    "#The CSV files are opened and manipulated by appending, so if this block is run more than once,\n",
    "#there will be redundant data.\n",
    "if os.path.exists(f'{currpath}/master.csv') is True:\n",
    "    raise NameError('Data is already stored locally')\n",
    "\n",
    "#Create CSVs\n",
    "master_file = open('master.csv', 'at')\n",
    "for key in dam_names:\n",
    "    dam = dam_names[key]\n",
    "    csv_file = open(f'{dam}_counts.csv', 'at')\n",
    "    \n",
    "#In the following block, the csv files of each year for each dam are appended to the dam's csv file.\n",
    "    for year in range(2006, 2023):\n",
    "        year = str(year)\n",
    "        \n",
    "#The CSV file is located at this url. I reformat the url based on the year and the dam abbreviation.\n",
    "        url = f'https://www.cbr.washington.edu/dart/cs/php/rpt/adult_daily.php?sc=1&outputFormat=csv&year={year}&proj={dam}&span=no&startdate=1%2F1&enddate=12%2F31&run=&syear={year}&eyear={year}'\n",
    "        req = requests.get(url)\n",
    "        \n",
    "#If there is no data for that year, the url will redirect to an error page.\n",
    "#If this happens, the year is skipped.\n",
    "        if url != req.url:\n",
    "            continue\n",
    "        url_content = req.text\n",
    "        \n",
    "#There is a 'Notes' section at the end of each file. Here, I slice out that portion of the string.\n",
    "        end_of_data = url_content.find('Notes:')\n",
    "        url_content = url_content[:end_of_data]\n",
    "        csv_file.write(url_content)\n",
    "        master_file.write(url_content)\n",
    "    csv_file.close()\n",
    "    print(f'{dam} done.')\n",
    "print('All files filled.')\n",
    "master_file.close()\n",
    "print('Master file filled.')\n",
    "\n",
    "#Create pandas database for each dam csv file, and master CSV file.\n",
    "BON = pd.read_csv('BON_counts.csv')\n",
    "TDA = pd.read_csv('TDA_counts.csv')\n",
    "JDA = pd.read_csv('JDA_counts.csv')\n",
    "MCN = pd.read_csv('MCN_counts.csv')\n",
    "PRD = pd.read_csv('PRD_counts.csv')\n",
    "WAN = pd.read_csv('WAN_counts.csv')\n",
    "RIS = pd.read_csv('RIS_counts.csv')\n",
    "RRH = pd.read_csv('RRH_counts.csv')\n",
    "WEL = pd.read_csv('WEL_counts.csv')\n",
    "MASTER = pd.read_csv('master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fafead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Cleaning\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff5a265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore Data\n",
    "\n",
    "MAS\n",
    "MAS.shape\n",
    "MAS.info\n",
    "MAS.columns\n",
    "MAS.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ac7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformat 1: Rename columns\n",
    "MAS = MAS.rename(\n",
    "    columns={\n",
    "        'Project': 'Location',\n",
    "        'Chin': 'Chinook',\n",
    "        'Sock': 'Sockeye',\n",
    "    })\n",
    "\n",
    "#Reformat 2: Remove all fish types that aren't adult salmon.\n",
    "#Only Chinook, Sockeye, and Coho are the ones I would eat for dinner !\n",
    "column_names = ['Location', 'Date', 'Chinook','Sockeye','Coho']\n",
    "MAS = MAS[column_names]\n",
    "\n",
    "#Reformat 3: Change null salmon counts to zeroes.\n",
    "MAS = MAS.fillna(0)\n",
    "\n",
    "#Reformat 4: Order entries by Date; then by Location.\n",
    "MAS = MAS.sort_values(by=['Date', 'Location'], ignore_index=True)\n",
    "\n",
    "#Reformat 5: Add total salmon count column.\n",
    "MAS['Total Salmon'] = (MAS['Chinook']+MAS['Sockeye']+MAS['Coho'])\n",
    "\n",
    "#Reformat 6: Include data from Apr to Oct only.\n",
    "\n",
    "\n",
    "#Reformat 7: Take average of all salmon count data points for each day of the year.\n",
    "ds2 = ds1.groupby('Date', as_index=False)['Total Salmon'].mean()\n",
    "ds2['Total Salmon'] = ds2['Total Salmon'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Data Analysis\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6e83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import simple dataset into Python\n",
    "os.chdir('./Code/SALMONQUEST/SalmonData')\n",
    "\n",
    "dataanalysispath = 'data_simple.csv'\n",
    "#Define simple dataset as ds.\n",
    "ds = pd.DataFrame(pd.read_csv(dataanalysispath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba24e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QUESTION:\n",
    "#What are the top 20 salmon totals and their corresponding dates?\n",
    "top_20_set = ds.sort_values(by='Total Salmon', ascending=False, ignore_index = True).head(20)\n",
    "\n",
    "#Top 20 salmon totals\n",
    "top_20_nums = list(top_20_set['Total Salmon'])\n",
    "\n",
    "#Top salmon count\n",
    "high_num = max(top_20_nums)\n",
    "\n",
    "#For each salmon count, what is it's percent value compared to the top salmon count?\n",
    "percentages = []\n",
    "for i in top_20_nums:\n",
    "    percentages.append((i/high_num)*100)\n",
    "    print(percentages[len(percentages)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Conclusions:\n",
    "Top 12 days are in July. Top day is July 8th.\n",
    "Compared to the day with the most salmon, only the top 7 days have 75% or more as many fish,\n",
    "and only the top 18 days have 50% or more as many fish. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Peaks and Quantify Change each day\n",
    "ds['Net Change'] = ds['Total Salmon'].diff()\n",
    "top_20_change = ds.sort_values(by='Net Change', ascending=False, ignore_index=True)\n",
    "top_20_change.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
